{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHXrtrmBFQCg",
        "outputId": "503d023f-8344-4fb0-81b9-097894ecb920"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current working directory: c:\\CALDARIUM\\Caldarium\\labeler_tools\n",
            "Files in current directory: ['bench', 'consent_json_converter.ipynb', 'consent_k_test.ipynb', 'intake_json_converter.ipynb', 'intake_k_test.ipynb', 'invoice_json_converter_v2.0.ipynb', 'invoice_k_test.ipynb']\n",
            "\n",
            "A count: 4 | B count: 4 | Overlap pairs: 4\n",
            "A count: 4 | B count: 4 | Overlap: 4\n",
            "Missing in A: []\n",
            "Missing in B: []\n"
          ]
        }
      ],
      "source": [
        "import os, json, re\n",
        "from datetime import datetime\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "\n",
        "# ===================== DEBUG: Check current directory =====================\n",
        "print(\"Current working directory:\", os.getcwd())\n",
        "print(\"Files in current directory:\", os.listdir('.'))\n",
        "print()\n",
        "# ===================== Paths =====================\n",
        "#ANN_A_DIR = \"/content/data/ann_A\"\n",
        "# ANN_A_DIR = \"json_intakes\"\n",
        "# #ANN_B_DIR = \"/content/data/ann_B\"\n",
        "# ANN_B_DIR = \"output_intake_forms\"\n",
        "# OUTPUT_DIR = \"/bench/output\"\n",
        "# os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "ANN_A_DIR = os.path.join(\"..\", \"json_intakes\")\n",
        "ANN_B_DIR = os.path.join(\"..\", \"output_intake_forms\")\n",
        "OUTPUT_DIR = \"bench/output\"  # This stays in labeler_tools folder\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "pat = re.compile(r\"^(intake_T\\d+_gen\\d+)(?:_.*)?\\.json$\", re.IGNORECASE)\n",
        "\n",
        "\n",
        "#pat = re.compile(r\"^(intake_T\\d+_gen\\d+)\\.json$\", re.IGNORECASE)\n",
        "pat = re.compile(r\"^(intake_T\\d+_gen\\d+)(?:_.*)?\\.json$\", re.IGNORECASE)\n",
        "\n",
        "# ===================== ID Extraction =====================\n",
        "# def list_ids(folder):\n",
        "#     ids, bad = [], []\n",
        "#     for fn in os.listdir(folder):\n",
        "#         if not fn.endswith(\".json\"): continue\n",
        "#         m = pat.match(fn)\n",
        "#         if m: ids.append(m.group(1))\n",
        "#         else: bad.append(fn)\n",
        "#     return set(ids), bad\n",
        "\n",
        "def list_ids(folder):\n",
        "    id_to_fn = {}\n",
        "    bad = []\n",
        "    for fn in os.listdir(folder):\n",
        "        if not fn.endswith(\".json\"):\n",
        "            continue\n",
        "        m = pat.match(fn)\n",
        "        if m:\n",
        "            cid = m.group(1)          # canonical id: intake_T1_gen1\n",
        "            id_to_fn[cid] = fn        # store the real filename\n",
        "        else:\n",
        "            bad.append(fn)\n",
        "    return id_to_fn, bad\n",
        "\n",
        "# ids_a, bad_a = list_ids(ANN_A_DIR)\n",
        "# ids_b, bad_b = list_ids(ANN_B_DIR)\n",
        "\n",
        "# overlap = sorted(ids_a & ids_b)\n",
        "# missing_in_b = sorted(ids_a - ids_b)\n",
        "# missing_in_a = sorted(ids_b - ids_a)\n",
        "\n",
        "# print(f\"A count: {len(ids_a)} | B count: {len(ids_b)} | Overlap pairs: {len(overlap)}\")\n",
        "# if bad_a: print(\"[WARN] A bad names:\", bad_a)\n",
        "# if bad_b: print(\"[WARN] B bad names:\", bad_b)\n",
        "# if missing_in_b: print(\"[WARN] Missing in B:\", missing_in_b)\n",
        "# if missing_in_a: print(\"[WARN] Missing in A:\", missing_in_a)\n",
        "\n",
        "ids_a, bad_a = list_ids(ANN_A_DIR)   # parser outputs\n",
        "ids_b, bad_b = list_ids(ANN_B_DIR)   # labeler GT\n",
        "\n",
        "overlap = sorted(set(ids_a.keys()) & set(ids_b.keys()))\n",
        "missing_in_b = sorted(set(ids_a.keys()) - set(ids_b.keys()))\n",
        "missing_in_a = sorted(set(ids_b.keys()) - set(ids_a.keys()))\n",
        "\n",
        "print(f\"A count: {len(ids_a)} | B count: {len(ids_b)} | Overlap pairs: {len(overlap)}\")\n",
        "if bad_a: print(\"[WARN] A bad names:\", bad_a)\n",
        "if bad_b: print(\"[WARN] B bad names:\", bad_b)\n",
        "if missing_in_b: print(\"[WARN] Missing in B:\", missing_in_b)\n",
        "if missing_in_a: print(\"[WARN] Missing in A:\", missing_in_a)\n",
        "\n",
        "# ===================== ID Extraction =====================\n",
        "ids_a, bad_a = list_ids(ANN_A_DIR)      # dict: {\"intake_T1_gen1\": \"intake_T1_gen1_hmgs_intake.json\"}\n",
        "ids_b, bad_b = list_ids(ANN_B_DIR)      # dict: {\"intake_T1_gen1\": \"intake_T1_gen1.json\"}\n",
        "\n",
        "overlap = sorted(set(ids_a.keys()) & set(ids_b.keys()))\n",
        "missing_in_b = sorted(set(ids_a.keys()) - set(ids_b.keys()))\n",
        "missing_in_a = sorted(set(ids_b.keys()) - set(ids_a.keys()))\n",
        "\n",
        "print(f\"A count: {len(ids_a)} | B count: {len(ids_b)} | Overlap: {len(overlap)}\")\n",
        "print(\"Missing in A:\", missing_in_a)\n",
        "print(\"Missing in B:\", missing_in_b)\n",
        "\n",
        "# ===================== NOW ADD YOUR K-HYBRID LOOP HERE =====================\n",
        "results = []   # example — store your disagreement rows here\n",
        "\n",
        "for cid in overlap:\n",
        "    # parser JSON (A)\n",
        "    with open(os.path.join(ANN_A_DIR, ids_a[cid]), \"r\") as fa:\n",
        "        a = json.load(fa)\n",
        "\n",
        "    # labeler ground truth (B)\n",
        "    with open(os.path.join(ANN_B_DIR, ids_b[cid]), \"r\") as fb:\n",
        "        b = json.load(fb)\n",
        "\n",
        "    # =====================================\n",
        "    # ADD YOUR FIELD-BY-FIELD COMPARISON\n",
        "    # =====================================\n",
        "\n",
        "    # Example (replace with your real comparison function):\n",
        "    for field in set(a.keys()) | set(b.keys()):\n",
        "        va = a.get(field)\n",
        "        vb = b.get(field)\n",
        "\n",
        "        if va != vb:\n",
        "            results.append({\n",
        "                \"consent_id\": cid,\n",
        "                \"field\": field,\n",
        "                \"A\": va,\n",
        "                \"B\": vb,\n",
        "            })\n",
        "\n",
        "# Convert to dataframe\n",
        "df = pd.DataFrame(results)\n",
        "df.to_csv(os.path.join(OUTPUT_DIR, \"intake_k_test_results.csv\"), index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "227IVnoZR3uh",
        "outputId": "211ddf5a-100d-4217-c5f4-9a8b9503e9b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Comparing 4 intake forms...\n",
            "Saved: bench/output\\qa_report_intake.csv\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>field</th>\n",
              "      <th>metric</th>\n",
              "      <th>value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>patient_dob</td>\n",
              "      <td>cohens_kappa</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>patient_dob</td>\n",
              "      <td>exact_match_rate</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>patient_name</td>\n",
              "      <td>cohens_kappa</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>patient_name</td>\n",
              "      <td>exact_match_rate</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>patient_phone</td>\n",
              "      <td>cohens_kappa</td>\n",
              "      <td>0.428571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>patient_phone</td>\n",
              "      <td>exact_match_rate</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>provider_name</td>\n",
              "      <td>cohens_kappa</td>\n",
              "      <td>0.692308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>provider_name</td>\n",
              "      <td>exact_match_rate</td>\n",
              "      <td>0.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>referral_name</td>\n",
              "      <td>cohens_kappa</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>referral_name</td>\n",
              "      <td>exact_match_rate</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           field            metric     value\n",
              "0    patient_dob      cohens_kappa  1.000000\n",
              "1    patient_dob  exact_match_rate  1.000000\n",
              "2   patient_name      cohens_kappa  1.000000\n",
              "3   patient_name  exact_match_rate  1.000000\n",
              "4  patient_phone      cohens_kappa  0.428571\n",
              "5  patient_phone  exact_match_rate  0.500000\n",
              "6  provider_name      cohens_kappa  0.692308\n",
              "7  provider_name  exact_match_rate  0.750000\n",
              "8  referral_name      cohens_kappa  1.000000\n",
              "9  referral_name  exact_match_rate  1.000000"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# # ===================== Config =====================\n",
        "# DATE_FORMATS = [\"%Y-%m-%d\", \"%m/%d/%Y\", \"%Y/%m/%d\", \"%m-%d-%Y\", \"%d-%b-%Y\", \"%b %d, %Y\"]\n",
        "# FNAME_PAT = re.compile(r\"^(intake_T\\d+_gen\\d+)\\.json$\", re.IGNORECASE)\n",
        "\n",
        "# FIELDS = [\n",
        "#     \"patient_name\", \"patient_dob\", \"patient_phone\", \"referral_name\", \"provider_name\"]\n",
        "\n",
        "# ===================== Config =====================\n",
        "DATE_FORMATS = [\"%Y-%m-%d\", \"%m/%d/%Y\", \"%Y/%m/%d\", \"%m-%d-%Y\", \"%d-%b-%Y\", \"%b %d, %Y\"]\n",
        "# Updated pattern to handle suffixes like _hmgs_intake\n",
        "FNAME_PAT = re.compile(r\"^(intake_T\\d+_gen\\d+)(?:_.*)?\\.json$\", re.IGNORECASE)\n",
        "\n",
        "FIELDS = [\n",
        "    \"patient_name\", \"patient_dob\", \"patient_phone\", \"referral_name\", \"provider_name\"]\n",
        "# ===================== Helpers =====================\n",
        "_ws = re.compile(r\"\\s+\")\n",
        "def norm_str(s):\n",
        "    if s is None: return None\n",
        "    s = str(s).strip().casefold()\n",
        "    return _ws.sub(\" \", s) or None\n",
        "\n",
        "def norm_phone(s):\n",
        "    if s is None: return None\n",
        "    ds = re.sub(r\"\\D+\", \"\", str(s))\n",
        "    return ds or None\n",
        "\n",
        "def parse_date(s):\n",
        "    if s is None: return None\n",
        "    s = str(s).strip()\n",
        "    if not s: return None\n",
        "    for fmt in DATE_FORMATS:\n",
        "        try: return datetime.strptime(s, fmt).date()\n",
        "        except: pass\n",
        "    try: return datetime.fromisoformat(s).date()\n",
        "    except: return None\n",
        "\n",
        "def norm_date(s):\n",
        "    d = parse_date(s)\n",
        "    return d.isoformat() if d else None\n",
        "\n",
        "# ===================== Record Normalization =====================\n",
        "def normalize_record(j, forced_id=None):\n",
        "    out = dict(j)\n",
        "    for f in FIELDS:\n",
        "        val = j.get(f)\n",
        "        if \"date\" in f or \"dob\" in f:\n",
        "            out[f] = norm_date(val)\n",
        "        elif \"phone\" in f:\n",
        "            out[f] = norm_phone(val)\n",
        "        else:\n",
        "            out[f] = norm_str(val)\n",
        "    # force id consistency\n",
        "    if forced_id:\n",
        "        out[\"consent_id\"] = forced_id\n",
        "    return out\n",
        "\n",
        "# ===================== Load =====================\n",
        "def load_by_full_id(folder):\n",
        "    data = {}\n",
        "    for fn in os.listdir(folder):\n",
        "        if not fn.endswith(\".json\"): continue\n",
        "        m = FNAME_PAT.match(fn)\n",
        "        if not m: continue\n",
        "        key = m.group(1)\n",
        "        with open(os.path.join(folder, fn), \"r\", encoding=\"utf-8\") as f:\n",
        "            j = json.load(f)\n",
        "        data[key] = normalize_record(j, forced_id=key)\n",
        "    return data\n",
        "\n",
        "# ===================== Metrics =====================\n",
        "def kappa(a,b):\n",
        "    A = [\"<MISSING>\" if v is None else str(v) for v in a]\n",
        "    B = [\"<MISSING>\" if v is None else str(v) for v in b]\n",
        "    n = len(A)\n",
        "    if n == 0: return None\n",
        "    po = sum(1 for x,y in zip(A,B) if x==y) / n\n",
        "    ca, cb = Counter(A), Counter(B)\n",
        "    pe = sum((ca[k]/n)*(cb[k]/n) for k in set(ca)|set(cb))\n",
        "    return 1.0 if pe == 1 else (po - pe) / (1 - pe)\n",
        "\n",
        "def exact(a,b):\n",
        "    n = len(a)\n",
        "    return None if n==0 else sum(1 for x,y in zip(a,b) if x==y)/n\n",
        "\n",
        "# ===================== Compare =====================\n",
        "data_a = load_by_full_id(ANN_A_DIR)\n",
        "data_b = load_by_full_id(ANN_B_DIR)\n",
        "\n",
        "ids_a, ids_b = set(data_a), set(data_b)\n",
        "overlap = sorted(ids_a & ids_b)\n",
        "print(f\"Comparing {len(overlap)} intake forms...\")\n",
        "\n",
        "summary = []\n",
        "def collect(field):\n",
        "    A = [data_a[i].get(field) for i in overlap]\n",
        "    B = [data_b[i].get(field) for i in overlap]\n",
        "    return A,B\n",
        "\n",
        "for f in FIELDS:\n",
        "    A,B = collect(f)\n",
        "    summary += [\n",
        "        {\"field\": f, \"metric\": \"exact_match_rate\", \"value\": exact(A,B)},\n",
        "        {\"field\": f, \"metric\": \"cohens_kappa\",     \"value\": kappa(A,B)},\n",
        "    ]\n",
        "\n",
        "df_summary = pd.DataFrame(summary).sort_values([\"field\",\"metric\"]).reset_index(drop=True)\n",
        "out_path = os.path.join(OUTPUT_DIR, \"qa_report_intake.csv\")\n",
        "df_summary.to_csv(out_path, index=False)\n",
        "\n",
        "print(\"Saved:\", out_path)\n",
        "display(df_summary.head(30))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "8S5Va_MO6LAK"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[0;32m      2\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "TWf1BnM5SJIP",
        "outputId": "80989f06-e197-49b6-f48f-dbe4ec762fe7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================== CONSENT QA SUMMARY ====================\n",
            "Hybrid QA Score: 0.840 → 83.97%\n",
            "Interpretation: Good (80–89%)\n",
            "============================================================\n",
            "Disagreement rows: 3\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>intake_id</th>\n",
              "      <th>field</th>\n",
              "      <th>A</th>\n",
              "      <th>B</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>intake_T1_gen1</td>\n",
              "      <td>patient_phone</td>\n",
              "      <td>8949753639</td>\n",
              "      <td>13525131229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>intake_T2_gen2</td>\n",
              "      <td>patient_phone</td>\n",
              "      <td>18122428971</td>\n",
              "      <td>14528504965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>intake_T2_gen2</td>\n",
              "      <td>provider_name</td>\n",
              "      <td>dr. holly porter</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        intake_id          field                 A            B\n",
              "0  intake_T1_gen1  patient_phone        8949753639  13525131229\n",
              "1  intake_T2_gen2  patient_phone       18122428971  14528504965\n",
              "2  intake_T2_gen2  provider_name  dr. holly porter         None"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# ===================== Hybrid QA Score =====================\n",
        "mean_kappa = df_summary[df_summary['metric']==\"cohens_kappa\"][\"value\"].mean()\n",
        "mean_exact = df_summary[df_summary['metric']==\"exact_match_rate\"][\"value\"].mean()\n",
        "\n",
        "# Simpler weight since no numeric or line items\n",
        "hybrid_score = 0.6 * mean_exact + 0.4 * mean_kappa\n",
        "\n",
        "def interpret(score):\n",
        "    if score >= 0.9: return \"Excellent (≥ 90%)\"\n",
        "    elif score >= 0.8: return \"Good (80–89%)\"\n",
        "    elif score >= 0.7: return \"Moderate (70–79%)\"\n",
        "    else: return \"Poor (< 70%)\"\n",
        "\n",
        "interpretation = interpret(hybrid_score)\n",
        "print(\"\\n==================== CONSENT QA SUMMARY ====================\")\n",
        "print(f\"Hybrid QA Score: {hybrid_score:.3f} → {hybrid_score*100:.2f}%\")\n",
        "print(f\"Interpretation: {interpretation}\")\n",
        "print(\"============================================================\")\n",
        "\n",
        "# ===================== Disagreement Report =====================\n",
        "def disagreement_report(overlap_ids, data_a, data_b, out_csv):\n",
        "    rows = []\n",
        "    for cid in overlap_ids:\n",
        "        na, nb = data_a[cid], data_b[cid]\n",
        "        for f in FIELDS:\n",
        "            va, vb = na.get(f), nb.get(f)\n",
        "            if va != vb:\n",
        "                rows.append({\"intake_id\": cid, \"field\": f, \"A\": va, \"B\": vb})\n",
        "    df = pd.DataFrame(rows)\n",
        "    if not df.empty:\n",
        "        df.to_csv(out_csv, index=False)\n",
        "    return df\n",
        "\n",
        "diff_path = os.path.join(OUTPUT_DIR, \"disagreements_consent.csv\")\n",
        "df_diff = disagreement_report(overlap, data_a, data_b, diff_path)\n",
        "print(\"Disagreement rows:\", len(df_diff))\n",
        "display(df_diff.head(25))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "wtyARMrpMHWU",
        "outputId": "7f65b322-0df0-4673-ace1-f1eb28762249"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mshutil\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m files\n\u001b[0;32m      4\u001b[0m zip_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(OUTPUT_DIR, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconsent_qa_results.zip\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m shutil\u001b[38;5;241m.\u001b[39mmake_archive(zip_path\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.zip\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzip\u001b[39m\u001b[38;5;124m\"\u001b[39m, OUTPUT_DIR)\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "zip_path = os.path.join(OUTPUT_DIR, \"consent_qa_results.zip\")\n",
        "shutil.make_archive(zip_path.replace(\".zip\", \"\"), \"zip\", OUTPUT_DIR)\n",
        "files.download(zip_path)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "caldarium",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

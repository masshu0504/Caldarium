from fastapi import APIRouter, File, UploadFile, HTTPException
from fastapi.responses import JSONResponse
import psycopg2
from datetime import datetime
from parser_prototype import preprocess_text, clean_and_convert, extract_fields, extract_line_items, parse_invoice, parse_pdf_bytes
import os
from pathlib import Path
from dotenv import load_dotenv
from typing import Any, Dict
import pdfplumber, re, json
from io import BytesIO
import hashlib
import logging
from audit_logger_v1 import validate_log_entry, audit_log
import uuid
from validate_invoices import validate
import io
from working_consent_parser import base_schema as consent_schema, parse_city_state_zip, assemble_patient_name, parse_nih_consent, parse_hipaa_consent
from invoice_parser import extract_amount, base_schema as invoice_schema, _parse_money_line_exact, _find_last_amount_line, parse_hot_springs, parse_rose_petal, parse_white_petal


env_path = Path('.') / '.env.example'

load_dotenv(dotenv_path=env_path)


routes = APIRouter()

@routes.get("/health")
async def health():
    return {"status": "OK"}


@routes.get("/ready")
async def ready():
    try:
        
        conn = psycopg2.connect(
            host=os.getenv("POSTGRES_HOST"),
            port=os.getenv("POSTGRES_PORT"),
            dbname=os.getenv("POSTGRES_DB"),
            user=os.getenv("POSTGRES_USER"),
            password=os.getenv("POSTGRES_PASSWORD")
        )
        cur = conn.cursor()
        cur.execute("SELECT 1;")  # simple query
        result = cur.fetchone()
        cur.close()
        conn.close()
        if result == (1,):
            return {"status": "DB connection OK"}
        else:
            return {"status": "DB connection failed"}
    except Exception as e:
        return {"status": f"DB connection failed", "error": str(e)}
    


DB_HOST = os.getenv("POSTGRES_HOST")
DB_PORT = os.getenv("POSTGRES_PORT")
DB_NAME = os.getenv("POSTGRES_DB")
DB_USER = os.getenv("POSTGRES_USER")
DB_PASS = os.getenv("POSTGRES_PASSWORD")
AUDIT_DB = os.getenv("POSTGRES_AUDIT_DB")

def get_db_connection():
    """Establishes and returns a psycopg2 database connection."""
    return psycopg2.connect(
        host=DB_HOST,
        port=DB_PORT,
        dbname=DB_NAME,
        user=DB_USER,
        password=DB_PASS
    )



def insert_data(data: Dict[str, Any], table: str = "parsed_data", doc_id: str = "") -> str:
    """
    Inserts data into the specified PostgreSQL table and returns the generated ID.
    
    Assumes a table structure like:
    CREATE TABLE parsed_data (
        id UUID PRIMARY KEY,
        created_at TIMESTAMP WITH TIME ZONE,
        extracted_data JSONB
    );
    """
    conn = None
    generated_id = None
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        
        # SQL to insert the extracted JSON data, capture the generated UUID, and 
        # use the database's clock for the timestamp (NOW()) for consistency.
        sql = f"""
        INSERT INTO {table} (id, created_at, extracted_data)
        VALUES (%s, NOW(), %s)
        RETURNING id;
        """
        
        # Use str(data) or json.dumps(data) if you were to use the actual JSON type.
        # Since we are just inserting a single JSON object, passing the dict directly 
        # often works if psycopg2 is configured, but casting to string/JSON is safer.
        import json
        json_data = json.dumps(data)
        
        cursor.execute(sql, (doc_id, json_data))
        
        # Fetch the ID that was generated by the database
        generated_id = cursor.fetchone()[0]
        
        conn.commit()
        cursor.close()
        return str(generated_id)
        
    except psycopg2.Error as e:
        if conn:
            conn.rollback()
        print(f"Database error during insert: {e}")
        # Re-raise the exception to be caught by the FastAPI route's handler
        raise
        
    finally:
        if conn:
            conn.close()




def insert_audit_log(data: Dict[str, Any], table: str = "audit_logs", id: str="") -> str:
    """
    Inserts data into the specified PostgreSQL table and returns the generated ID.
    
    Assumes a table structure like:
    CREATE TABLE audit_logs (
        id SERIAL PRIMARY KEY,
        timestamp TIMESTAMP WITH TIME ZONE NOT NULL,  -- time of action (ISO format)
        doc_id TEXT NOT NULL,                         -- file name
        run_id TEXT NOT NULL,                         -- identifier for run instance
        role TEXT CHECK (role IN ('api', 'parser', 'validator', 'benchmark', 'labeler')) NOT NULL,
        actor TEXT NOT NULL,                          -- shortened actor name (e.g., m_oh)
        action TEXT NOT NULL,                         -- action performed
        field TEXT,                                   -- JSON field where action occurred (nullable)
        "from" TEXT,                                  -- original value (nullable)
        "to" TEXT,                                    -- new value (nullable)
        status TEXT CHECK (status IN ('success', 'fail', 'corrected', 'approved', 'skipped')) NOT NULL,
        schema_version TEXT DEFAULT 'invoice_v1_reset' NOT NULL,  -- schema version
        meta JSONB,                                   -- JSON metadata (e.g., parser_version)
        created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
    );
    """
    
    conn = None
    generated_id = None
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        
        # SQL to insert the extracted JSON data, capture the generated UUID, and 
        # use the database's clock for the timestamp (NOW()) for consistency.
        filename = data["file_metadata"]["original_filename"]

        actor = data.get("actor", "parser") # Providing a default
        schema_version = data.get("schema_version") # Can be None
        doc_id = data.get("doc_id")
        event_type = data.get("event_type")

        # The 'meta' column should store the full data dict as JSON
        json_data_for_meta = json.dumps(data)
        sql = f"""
        INSERT INTO {table} (
            id,
            timestamp,
            doc_id,
            run_id,
            role,
            actor,
            action,
            field,
            "from",
            "to",
            status,
            schema_version,
            meta,
            event_type
        )
        VALUES (
        %s,
        NOW(),       -- timestamp
        %s,          -- doc_id (from filename)
        %s,          -- run_id (from doc_id param)
        'parser',    -- role (as a string literal)
        %s,          -- actor (as a variable)
        'parser',    -- action (as a string literal)
        'parser',    -- field (as a string literal)
        'parse_api', -- "from" (as a string literal)
        'parsed_data_db', -- "to" (as a string literal)
        'success',   -- status (as a string literal)
        COALESCE(%s, 'invoice_v1_reset'), -- schema_version
        %s           -- meta (the full JSON data),
        %s
        )
        RETURNING status;
    """
        
        values_tuple = (
        id,
        filename,           # for doc_id
        doc_id,             # for run_id
        actor,              # for actor
        schema_version,     # for schema_version
        json_data_for_meta,  # for meta
        event_type
        )
        
        # 4. Execute by passing the SQL and the values tuple
        cursor.execute(sql, values_tuple)
        
        
        # Fetch the ID that was generated by the database
        generated_id = cursor.fetchone()[0]
        
        conn.commit()
        cursor.close()
        return str(generated_id)
        
    except psycopg2.Error as e:
        if conn:
            conn.rollback()
        print(f"Database error during insert: {e}")
        # Re-raise the exception to be caught by the FastAPI route's handler
        raise
        
    finally:
        if conn:
            conn.close()
    


def get_data_by_id(record_id: str) -> dict | None:
    """
    Fetches a single record from the database by its primary key.

    Args:
        record_id: The unique identifier for the record to retrieve.

    Returns:
        A dictionary representing the database row if found, otherwise None.
    """
    conn = None
    try:
        # Establish a connection to the database
        conn = get_db_connection()
        
        # Use a 'with' statement for the cursor to ensure it's closed automatically
        with conn.cursor() as cursor:
            # IMPORTANT: Use parameterized queries to prevent SQL injection.
            # The '%s' is a placeholder, not a Python string format.
            query = f"SELECT * FROM parsed_data WHERE id = %s;"
            cursor.execute(query, (record_id,))
            
            # Fetch one result
            record = cursor.fetchone()
            
            if not record:
                return None # No record was found with that ID

            # Get column names from the cursor description
            column_names = [desc[0] for desc in cursor.description]
            
            # Combine column names with the record's values to create a dictionary
            return dict(zip(column_names, record))

    except psycopg2.Error as e:
        print(f"Database error in get_data_by_id: {e}")
        # Re-raise the exception or handle it as needed; here we return None
        return None
    finally:
        # Ensure the connection is closed even if an error occurs
        if conn:
            conn.close()


    
@routes.post("/v1/parse")
async def parse(file: UploadFile = File(...)):
    try: 
        filename = file.filename
        if "invoice" in filename:
            content_type = file.content_type
            contents = await file.read()
            if validate(io.BytesIO(contents)):
                file_hash = hashlib.sha256(contents).hexdigest()

                data = parse_hot_springs(contents)
                data = parse_rose_petal(contents)
                data = parse_white_petal(contents)
                # Return Success Response ---
                if (
                    data.get("patient_name") is None and
                    data.get("patient_first_name") is None and
                    data.get("patient_middle_name") is None and
                    data.get("patient_last_name") is None and
                    data.get("patient_address_name") is None and
                    data.get("patient_id") is None and
                    data.get("patient_dob") is None and
                    data.get("patient_signature") is None and
                    data.get("patient_state") is None and
                    data.get("patient_city") is None and
                    data.get("patient_zip_code") is None and
                    data.get("provider_name") is None and
                    data.get("provider_address_name") is None and
                    data.get("provider_phone") is None and
                    data.get("provider_fax") is None and
                    data.get("provider_state") is None and
                    data.get("provider_city") is None and
                    data.get("provider_zip_code") is None and
                    data.get("family_name") is None and
                    data.get("family_relation") is None and
                    data.get("family_phone") is None and
                    data.get("family_address_name") is None and
                    data.get("family_state") is None and
                    data.get("family_city") is None and
                    data.get("family_zip_code") is None and
                    data.get("guardian_name") is None and
                    data.get("guardian_signature") is None and
                    data.get("guardian_relation") is None and
                    data.get("date") is None and
                    data.get("expiration_date") is None and
                    data.get("expiration_event") is None and
                    data.get("translator_name") is None and
                    data.get("translator_signature") is None

                ):
                    return JSONResponse(
                    status_code=422,
                    content={
                        "status" : "failed to extract all required fields", 
                        "error": 422
                    }
                )
                else:
                    random_id = uuid.uuid4().hex
                    inserted_id = insert_data(data=extracted_data, doc_id=random_id)
                    status = insert_audit_log(data=extracted_data, id=random_id)
                    return {
                        "status": "success",
                        "message": "File parsed and data stored successfully.",
                        "db_id": inserted_id,
                        "extracted_data": extracted_data, # Return the data to confirm storage
                        "audit_log_status": status
                    }
            else:
                return JSONResponse(
                    status_code=422,
                    content={
                        "status": "failed invoice validation",
                        "error": 422
                    }
                )
            

        elif "consent" in filename:
            content_type = file.content_type
            contents = await file.read()
            #file_hash = hashlib.sha256(contents).hexdigest()

            # uses parser*
            
            if "NIH Occupational" in contents:
                parsed = parse_nih_consent(contents)
            elif "HIPAA Authorization" in contents:
                parsed = parse_hipaa_consent(contents)
            else:
                parsed = consent_schema()
            size = len(contents)

            if (
                    data.get("invoice_number") is None and
                    data.get("patient_id") is None and
                    data.get("invoice_date") is None and
                    data.get("due_date") is None and
                    data.get("patient_name") is None and
                    data.get("patient_age") is None and
                    data.get("patient_address") is None and
                    data.get("patient_phone") is None and
                    data.get("patient_email") is None and
                    data.get("admission_date") is None and
                    data.get("discharge_date") is None and
                    data.get("subtotal_amout") is None and
                    data.get("discount_amount") is None and
                    data.get("total_amount") is None and
                    data.get("provider_name") is None and
                    data.get("bed_id") is None and
                    data.get("line_items") is None
                ):
                    return JSONResponse(
                    status_code=422,
                    content={
                        "status" : "failed to extract all required fields", 
                        "error": 422
                    }
                )

            random_id = uuid.uuid4().hex
            inserted_id = insert_data(data=parsed, doc_id=random_id)
            status = insert_audit_log(data=parsed, id=random_id)

            
            # Return Success Response ---
            return {
                "status": "success",
                "message": "File parsed and data stored successfully.",
                "db_id": inserted_id,
                "extracted_data": parsed, # Return the data to confirm storage
                "audit_log_status": status
            }
            
        elif "intake" in filename:
            content_type = file.content_type
            contents = await file.read()
            file_hash = hashlib.sha256(contents).hexdigest()

            # uses parser*
            data = parse_pdf_bytes(contents)

            size = len(contents)
            # change after getting parser
            
            invoice_number = data.get("invoice_number") 
            #patient_id = 0
            subtotal_amount = data.get("subtotal_amount")
            invoice_date = data.get("invoice_date")
            total_amount = data.get("total_amount")
            line_items = data.get("line_items")

            due_date = data.get("due_date")
            patient_name = data.get("patient_name")
            patient_age = data.get("patient_age")
            patient_address = data.get("patient_address")
            patient_phone = 0
            patient_email = 0
            admission_date = data.get("admission_date")
            discharge_date = data.get("discharge_date")
            discount_amount = data.get("discount_amount")
            bed_no = 0
            provider_name = 0
            provider_email = 0
            provider_website = 0
            account_no = 0
            hospital_no = 0
            bed_no = 0
            consultant = 0
            billed_to_address = 0
            tax_percent = data.get("tax_percent")
            tax_amount = 0
            currency = 0
            payment_instructions = 0
            disclaimer = 0
            total_amount = data.get("total_amount")



            extracted_data = {
                "invoice_number": invoice_number,
                "subtotal_amount": subtotal_amount,
                "invoice_date": invoice_date,
                "total_amount": total_amount,
                "line_items": line_items,
                "patient_name": patient_name,
                "patient_age": patient_age,
                "patient_address": patient_address,
                "admission_date": admission_date,
                "discharge_date": discharge_date,
                "discount_amount": discount_amount,
                "due_date": due_date,
                "file_metadata": {
                    "original_filename": filename,
                    "file_size_bytes": size,
                    "content_type": content_type,
                    "hash": file_hash
                }
            }

            if (invoice_number is None and
            subtotal_amount is None and
            invoice_date is None and
            total_amount is None and
            line_items is None and
            patient_name is None and
            patient_age is None and
            patient_address is None and
            admission_date is None and
            discharge_date is None and
            discount_amount is None and
            due_date is None):
                return JSONResponse(
                    status_code=422,
                    content={
                        "status" : "failed to extract all required fields", 
                        "error": 422
                    }
                )
            else:
                random_id = uuid.uuid4().hex
                inserted_id = insert_data(data=extracted_data, doc_id=random_id)
                status = insert_audit_log(data=extracted_data, id=random_id)
                # Return Success Response ---
                return {
                    "status": "success",
                    "message": "File parsed and data stored successfully.",
                    "db_id": inserted_id,
                    "extracted_data": extracted_data, # Return the data to confirm storage
                    "audit_log_status": status
                }
            
    except psycopg2.Error as e:
        # Handle PostgreSQL specific errors
        print(f"PostgreSQL Error: {e}")
        return JSONResponse(
            status_code=500,
            content={"status": "error", "message": "A database error occurred during storage."}
        )
    except Exception as e:
        # Handle general errors (file read error, JSON parsing error, etc.)
        print(f"General Error: {e}")
        return JSONResponse(
            status_code=500,
            content={"status": "error", "message": f"An unexpected error occurred: {str(e)}"}
        )


@routes.get("/v1/runs/{run_id}")
async def get_parsed_data(run_id: str):
    """
    Retrieves parsed invoice data by its unique database ID.
    """
    try:
        # 1. Fetch the complete record from your database
        db_record = get_data_by_id(run_id)

        if not db_record:
            raise HTTPException(status_code=404, detail="Record not found")

        # 2. Separate the metadata from the main parser data
        metadata = db_record.pop("file_metadata", {}) # Use .pop() to remove it from the main dict

        # 3. Structure the response exactly as requested
        response_data = {
            "data": db_record # The rest of the record is the parser JSON
        }
        
        return response_data

    except Exception as e:
        print(f"Error fetching record {run_id}: {e}")


@routes.get("/v1/report/template_detection")
async def template_detection_report():
    pass

@routes.get("/v1/report/duplicate_detection")
async def duplicate_detection_report():
    conn = get_db_connection()
    cursor = conn.cursor()
    cursor.execute("SELECT id, extracted_data FROM parsed_data")
    rows = cursor.fetchall()

    seen = set()
    duplicates = []

    for row_id, extracted in rows:
        canonical = json.dumps(extracted, sort_keys=True)
        h = hash(canonical)

        if h in seen:
            duplicates.append(row_id)
        else:
            seen.add(h)
    if len(duplicates) >= 1:
        return {
            "status": "success",
            "duplicates": duplicates
        }
    else:
        return {
            "status": "no duplicates found"
        }
